{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from cupy.cuda import Device\n",
    "from text_vae.cvae import RnnVae\n",
    "from text_vae.metrics import Evaluator\n",
    "from sklearn.datasets.lfw import Bunch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from collections import UserList, defaultdict\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from text_vae.corpus import SSTCorpus, WikiText2Corpus, IMDBCorpus\n",
    "from text_vae.misc import KLAnnealer, CosineAnnealingLRWithRestart, Logger, LogPlotter, reject_outliers, SamplePlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Bunch(\n",
    "    save='vae.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  4 22:40:13 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 49%   66C    P0    67W / 250W |     19MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 85%   91C    P2    95W / 250W |  10608MiB / 11172MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:42:00.0 Off |                  N/A |\n",
      "| 85%   90C    P2    86W / 250W |   9788MiB / 11172MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:43:00.0 Off |                  N/A |\n",
      "| 32%   60C    P8    22W / 250W |     19MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2417      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    1      2417      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    1     30732      C   python                                     10589MiB |\n",
      "|    2      2417      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    2     30732      C   python                                      9769MiB |\n",
      "|    3      2417      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Bunch(\n",
    "    # Model\n",
    "    model=Bunch(\n",
    "        q=Bunch(\n",
    "            cell='gru',\n",
    "            d_h=64,\n",
    "            n_layers=2,\n",
    "            r_dropout=0.0,  # should be around 0 to help encoder train more easily\n",
    "            s_dropout=0.0  # same as `r_dropout`\n",
    "        ),\n",
    "        g=Bunch(\n",
    "            cell='gru',\n",
    "            n_layers=2,\n",
    "            r_dropout=0.3,\n",
    "            s_dropout=0.0\n",
    "        ),\n",
    "        d=Bunch(\n",
    "            n_filters=3\n",
    "        ),\n",
    "        d_z=64,\n",
    "        d_c=2,\n",
    "        n_len=30 + 2,  # + <bos> and <eos>\n",
    "        n_vocab=10000,  # 'up to' value\n",
    "        d_emb=50,\n",
    "        p_word_dropout=0.3,\n",
    "        freeze_embeddings=False,\n",
    "        attention=True\n",
    "    ),\n",
    "    # Train\n",
    "    train=Bunch(\n",
    "        n_batch=64,\n",
    "        n_iter_per_epoch=5000,  # n_epoch will be calcaulated based on lr setting\n",
    "        grad_clipping=5,\n",
    "        kl=Bunch(\n",
    "            i_start=1,\n",
    "            w_start=1e-3,\n",
    "            w_max=0.4\n",
    "        ),\n",
    "        lr=Bunch(\n",
    "            value=1e-2,\n",
    "            scheduler=Bunch(\n",
    "                n_period=10,\n",
    "                n_r=1,  # number of restarts in SGDR\n",
    "                n_mult=2,\n",
    "                lr_min=1e-3\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    # Val\n",
    "    val=Bunch(\n",
    "        sample_params=Bunch(\n",
    "            n_beam=1,\n",
    "            coverage_penalty=False\n",
    "        ),\n",
    "        n_hypot=100,\n",
    "        n_ref=500\n",
    "    ),\n",
    "    # Env\n",
    "    device_code=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    f'cuda:{args.device_code}' \n",
    "    if args.device_code >= 0 and torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "Device(device.index).use()  # cupy for SRU to work\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.84 s, sys: 88.1 ms, total: 2.93 s\n",
      "Wall time: 2.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5983, 769, 1605, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sents with targets\n",
    "%time corpus = SSTCorpus(**args.model, n_batch=args.train.n_batch, device=device)\n",
    "# LM\n",
    "# %time corpus = WikiText2Corpus(**args.model, n_batch=args.train.n_batch, device=device)\n",
    "# Sents with targets, `val` same as `test` (so we overfit a bit), `unlabeled` xs same as `labeled` xs\n",
    "# %time corpus = IMDBCorpus(**args.model, n_batch=args.train.n_batch, device=device)\n",
    "corpus.size('train'), corpus.size('val'), corpus.size('test'), len(corpus.vocab('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RnnVae(\n",
       "  (x_emb): Embedding(10000, 50, padding_idx=1)\n",
       "  (encoder_rnn): GRU(50, 64, num_layers=2)\n",
       "  (q_mu): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (q_logvar): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (decoder_rnn): GRU(116, 66, num_layers=2, dropout=0.3)\n",
       "  (decoder_a): SelfAttention(\n",
       "    (linear_in): Linear(in_features=66, out_features=66, bias=False)\n",
       "    (linear_out): Linear(in_features=132, out_features=66, bias=False)\n",
       "    (activation): SELU()\n",
       "  )\n",
       "  (decoder_fc): Linear(in_features=66, out_features=10000, bias=True)\n",
       "  (disc_cnn): CNNEncoder(\n",
       "    (_activation): ReLU()\n",
       "    (conv_layer_0): Conv1d(2, 3, kernel_size=(2,), stride=(1,))\n",
       "    (conv_layer_1): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
       "    (conv_layer_2): Conv1d(2, 3, kernel_size=(4,), stride=(1,))\n",
       "    (conv_layer_3): Conv1d(2, 3, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (encoder): ModuleList(\n",
       "    (0): GRU(50, 64, num_layers=2)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): GRU(116, 66, num_layers=2, dropout=0.3)\n",
       "    (1): SelfAttention(\n",
       "      (linear_in): Linear(in_features=66, out_features=66, bias=False)\n",
       "      (linear_out): Linear(in_features=132, out_features=66, bias=False)\n",
       "      (activation): SELU()\n",
       "    )\n",
       "    (2): Linear(in_features=66, out_features=10000, bias=True)\n",
       "  )\n",
       "  (vae): ModuleList(\n",
       "    (0): Embedding(10000, 50, padding_idx=1)\n",
       "    (1): ModuleList(\n",
       "      (0): GRU(50, 64, num_layers=2)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): GRU(116, 66, num_layers=2, dropout=0.3)\n",
       "      (1): SelfAttention(\n",
       "        (linear_in): Linear(in_features=66, out_features=66, bias=False)\n",
       "        (linear_out): Linear(in_features=132, out_features=66, bias=False)\n",
       "        (activation): SELU()\n",
       "      )\n",
       "      (2): Linear(in_features=66, out_features=10000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (discriminator): ModuleList(\n",
       "    (0): CNNEncoder(\n",
       "      (_activation): ReLU()\n",
       "      (conv_layer_0): Conv1d(2, 3, kernel_size=(2,), stride=(1,))\n",
       "      (conv_layer_1): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
       "      (conv_layer_2): Conv1d(2, 3, kernel_size=(4,), stride=(1,))\n",
       "      (conv_layer_3): Conv1d(2, 3, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RnnVae(\n",
    "    **args.model, \n",
    "    x_vocab=corpus.vocab('x')\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recording preciousness own shatner surprises justifies mouth team populates overmanipulative obscenity fluid cameos concoction quentin carol beneath photography dystopian trapped boxes trademark fatale guaranteed descends egoyan creek sumptuous 101 third stretched'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = lambda s: corpus.reverse(model.sample_sentence(s, **args.val.sample_params)[2])\n",
    "evaluator = Evaluator(corpus, args.val.n_ref, sample_params=args.val.sample_params)\n",
    "sampler(1)[0]  # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epoch = sum(args.train.lr.scheduler.n_period * (args.train.lr.scheduler.n_mult ** i)\n",
    "              for i in range(args.train.lr.scheduler.n_r))\n",
    "kl_annealer = KLAnnealer(**args.train.kl, n_epoch=n_epoch)\n",
    "xs = np.linspace(0, n_epoch, num=n_epoch + 1)\n",
    "ts = np.array([kl_annealer(i) for i in xs])\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('kl weight')\n",
    "plt.plot(xs, ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params = lambda: (p for p in model.vae.parameters() if p.requires_grad)\n",
    "trainer = optim.Adam(get_params(), lr=args.train.lr.value)\n",
    "lr_scheduler = CosineAnnealingLRWithRestart(trainer, **args.train.lr.scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bf96ab8a214b37b51330c228a6b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "rnn: hx is not contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96b26b57c86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hypot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mself_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hypot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     elog.append({\n\u001b[1;32m     54\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'loss'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text_gen/text_vae/metrics.py\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(self, model, split)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unlabeled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_c_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text_gen/text_vae/cvae.py\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(self, x, use_c_prior, max_ppl)\u001b[0m\n\u001b[1;32m    525\u001b[0m         outputs, _ = self.decoder_rnn(\n\u001b[1;32m    526\u001b[0m             \u001b[0mx_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mh_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         )  # (n_len, n_batch, d_z + d_c)\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_gen/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_gen/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_gen/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_gen/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: rnn: hx is not contiguous"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "batcher = corpus.batcher('train', 'unlabeled')\n",
    "T = tqdm.tqdm_notebook(range(n_epoch))\n",
    "n_iter = args.train.n_iter_per_epoch\n",
    "elog, ilog = Logger(), Logger()\n",
    "\n",
    "for epoch in T:\n",
    "    # Epoch start\n",
    "    kl_weight = kl_annealer(epoch)\n",
    "    \n",
    "    # Iters\n",
    "    for i in range(n_iter):\n",
    "        # Forward\n",
    "        x = next(batcher)\n",
    "        kl_loss, recon_loss = model(x, use_c_prior=True)\n",
    "        loss = kl_weight * kl_loss + recon_loss\n",
    "        \n",
    "        # Backward\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(get_params(), args.train.grad_clipping)\n",
    "        trainer.step()\n",
    "        \n",
    "        # Log\n",
    "        lr = trainer.param_groups[0]['lr']\n",
    "        ilog.append({\n",
    "            'epoch': epoch,\n",
    "            'kl_loss': kl_loss.item(),\n",
    "            'recon_loss': recon_loss.item(),\n",
    "            'loss': loss.item(),\n",
    "            'kl_weight': kl_weight,\n",
    "            'lr': lr\n",
    "        })\n",
    "        \n",
    "        # Update T\n",
    "        kl_loss_value = np.mean(reject_outliers(ilog['kl_loss'][-args.train.n_iter_per_epoch:]))\n",
    "        recon_loss_value = np.mean(reject_outliers(ilog['recon_loss'][-args.train.n_iter_per_epoch:]))\n",
    "        loss_value = np.mean(reject_outliers(ilog['loss'][-args.train.n_iter_per_epoch:]))\n",
    "        postfix_strs = []\n",
    "        postfix_strs.append(f'i={i}/{n_iter}')\n",
    "        postfix_strs.append(f'kl_loss={kl_loss_value:.5f}')\n",
    "        postfix_strs.append(f'recon_loss={recon_loss_value:.5f}')\n",
    "        postfix_strs.append(f'loss={loss_value:.5f}')\n",
    "        postfix_strs.append(f'klw={kl_weight:.3f} lr={lr:.5f}')\n",
    "        T.set_postfix_str(' '.join(postfix_strs))\n",
    "        T.refresh()\n",
    "    \n",
    "    # Log\n",
    "    sent = sampler(1)[0]\n",
    "    bleu = evaluator.bleu(model, args.val.n_hypot, 'val')\n",
    "    self_bleu = evaluator.self_bleu(model, args.val.n_hypot)\n",
    "    ppl = evaluator.perplexity(model, 'val')\n",
    "    elog.append({\n",
    "        **{k: v for k, v in ilog[-1].items() if 'loss' not in k},\n",
    "        'kl_loss': kl_loss_value,\n",
    "        'recon_loss': recon_loss_value,\n",
    "        'loss': loss_value,\n",
    "        'sent': sent,\n",
    "        'bleu': bleu,\n",
    "        'self_bleu': self_bleu,\n",
    "        'ppl': ppl\n",
    "    })\n",
    "    \n",
    "    # Print result\n",
    "    bleu_5, self_bleu_5 = bleu['5-gram'], self_bleu['5-gram']\n",
    "    print(f\"[epoch={epoch}, bleu_5={bleu_5:.3f} self_bleu_5={self_bleu_5:.3f} ppl={ppl:.3f}]: '{sent}'\")\n",
    "    \n",
    "    # Epoch end\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = LogPlotter(elog)\n",
    "plotter.grid([\n",
    "    'kl_loss', 'recon_loss',\n",
    "    'loss', 'lr',\n",
    "    'bleu', 'self_bleu',\n",
    "    'epoch', 'ppl'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splotter = SamplePlotter(corpus, model, sample_params=args.val.sample_params)\n",
    "splotter.plot_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time evaluator.bleu(model, args.val.n_hypot, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time evaluator.bleu(model, args.val.n_hypot, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time evaluator.self_bleu(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.self_bleu(model, args.val.n_hypot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((args, model), path.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh {path.save}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
