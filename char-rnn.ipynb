{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "from hyperdash import Experiment\n",
    "from contextlib import redirect_stdout, redirect_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot\n",
    "from keras.utils import to_categorical, print_summary, plot_model, Sequence\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dense, TimeDistributed, Activation, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ACTIVE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r descs\n",
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Save current cursor selection and return position bounds',\n",
       " 'Create a :class:`GoogleAPICallError` from a :class:`requests.Response`. DCNL Args: DCNL response (requests.Response): The HTTP response. DCNL Returns: DCNL GoogleAPICallError: An instance of the appropriate subclass of DCNL :class:`GoogleAPICallError`, with the message and errors populated DCNL from the response.',\n",
       " 'Test the error response when the activity_create API is called DCNL with an authorization header for a user who is not authorized to DCNL create activities.',\n",
       " 'Get a permitted action by its dict key or action name',\n",
       " 'Called when a moderator accepts a comment. After the method is DCNL called the comment should be displayed to all users. DCNL :param comment_id: The id of the comment being accepted.',\n",
       " 'increment the current intensity and reset counter',\n",
       " 'Executes the FTP NLST command on the given path.',\n",
       " 'Return an iterator over the values in the dictionary.  Values are DCNL iterated over in sorted order of the keys. DCNL Iterating views while adding or deleting entries in the dictionary may DCNL raise a `RuntimeError` or fail to iterate over all entries.',\n",
       " 'RawIMU object constructor.',\n",
       " 'Return the minions found by looking via ipcidr']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(descs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = max(len(desc) for desc in descs)\n",
    "MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_split(descs):\n",
    "    chars = list(set(chain.from_iterable(desc for desc in descs)))\n",
    "    char_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "    ix_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    descs = [[char_ix[char] for char in desc] for desc in descs]\n",
    "    return descs, char_ix, ix_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 60 ms, total: 1.73 s\n",
      "Wall time: 1.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('o', 0), ('*', 1), ('m', 2), ('(', 3), ('z', 4)],\n",
       " [(0, 'o'), (1, '*'), (2, 'm'), (3, '('), (4, 'z')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time descs, dir_map, rev_map = chars_split(descs)\n",
    "list(dir_map.items())[:5], list(rev_map.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(dir_map)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TT prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSequence(Sequence):\n",
    "    def __init__(self):\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(descs) / BATCH_SIZE))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_ids = self._ids[idx * BATCH_SIZE: (idx + 1) * BATCH_SIZE]\n",
    "        seq_len = max(len(descs[di]) for di in batch_ids)\n",
    "        X = np.zeros((BATCH_SIZE, seq_len, VOCAB_SIZE))\n",
    "        y = np.zeros_like(X)\n",
    "        \n",
    "        for bi, di in enumerate(batch_ids):\n",
    "            for pi, wi in enumerate(descs[di]):\n",
    "                X[bi, pi, wi] = 1\n",
    "            \n",
    "            for pi, wi in enumerate(descs[di][1:]):\n",
    "                y[bi, pi, wi] = 1\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Generate new shuffle in between epochs.\"\"\"\n",
    "        self._ids = np.random.permutation(len(descs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2674, (64, 452, 95), (64, 452, 95))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = TTSequence()\n",
    "len(tts), tts[0][0].shape, tts[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 100\n",
    "N_LAYERS = 1\n",
    "LSTM_CLASS = GRU  # LSTM if not GPU_ACTIVE else CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, None, 100)         58800     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 95)          9595      \n",
      "=================================================================\n",
      "Total params: 68,395\n",
      "Trainable params: 68,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM_CLASS(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), \n",
    "                     dropout=0.3, return_sequences=True))\n",
    "for i in range(N_LAYERS - 1):\n",
    "    model.add(LSTM_CLASS(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDLoss(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.exp = Experiment('2.1.1: ChaRNN convergence', capture_io=False)\n",
    "        \n",
    "        # SUPER-hacky, but it's work (needed to supress hd output)\n",
    "        self.exp._hd.out_buf.write = lambda _: _\n",
    "    \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.exp.end()\n",
    "\n",
    "    def on_batch_end(self, n_batch, logs={}):\n",
    "        self.exp.metric('n_batch', n_batch)\n",
    "        self.exp.metric('loss', logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2674/2674 [==============================] - 1763s 659ms/step - loss: 0.5219\n",
      "Epoch 2/5\n",
      "2674/2674 [==============================] - 1796s 672ms/step - loss: 0.4291\n",
      "Epoch 3/5\n",
      "2674/2674 [==============================] - 1758s 657ms/step - loss: 0.4037\n",
      "Epoch 4/5\n",
      "2674/2674 [==============================] - 1750s 655ms/step - loss: 0.3913\n",
      "Epoch 5/5\n",
      "2674/2674 [==============================] - 1761s 659ms/step - loss: 0.3826\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(TTSequence(), verbose=1, epochs=5,\n",
    "                    callbacks=[HDLoss()],\n",
    "                    use_multiprocessing=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length):\n",
    "    \"\"\"Generate text with specific length.\"\"\"\n",
    "    assert length >= 1\n",
    "    \n",
    "    ix = [np.random.randint(VOCAB_SIZE)]\n",
    "    ys = [rev_map[ix[-1]]]\n",
    "    X = np.zeros((1, length, VOCAB_SIZE))\n",
    "    \n",
    "    for i in range(length - 1):\n",
    "        X[0, i, ix[-1]] = 1\n",
    "        ix = np.argmax(model.predict(X[:, :i + 1, :])[0], 1)\n",
    "        ys.append(rev_map[ix[-1]])\n",
    "    \n",
    "    return ''.join(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Query and returns a service is a service DCNL'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
