{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171161"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r descs\n",
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Returns the instanciated workflow class.',\n",
       " 'Loads the Grunfeld data and returns a Dataset class. DCNL Returns DCNL Dataset instance: DCNL See DATASET_PROPOSAL.txt for more information. DCNL Notes DCNL raw_data has the firm variable expanded to dummy variables for each DCNL firm (ie., there is no reference dummy)',\n",
       " 'Parse a list of tokens (typically the content of a function token) DCNL as arguments made of a single token each, separated by mandatory commas, DCNL with optional white space around each argument. DCNL return the argument list without commas or white space; DCNL or None if the function token content do not match the description above.',\n",
       " 'Test if it returns True when user already exists in htpasswd file',\n",
       " 'Initialize the InfluxDBServerError handler.',\n",
       " 'Test for List everything added for or enabled in all zones',\n",
       " 'Propagate status updates of the case to high-risk contacts',\n",
       " 'Stops profiler execution by sending a SIGTERM to kvm_stat process. DCNL :param test: Autotest test on which this profiler will operate on.',\n",
       " 'Conversion from non-square sparse array.',\n",
       " \"delete a parent directory from sickbeard\\\\'s config\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(descs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_split(descs):\n",
    "    chars = list(set(chain.from_iterable(desc for desc in descs)))\n",
    "    char_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "    ix_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    descs = [[char_ix[char] for char in desc] for desc in descs]\n",
    "    return descs, char_ix, ix_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 96 ms, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%time descs, dir_map, rev_map = chars_split(descs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TT prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
