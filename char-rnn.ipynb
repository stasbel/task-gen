{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot\n",
    "from keras.utils import to_categorical, print_summary, plot_model, Sequence\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dense, TimeDistributed, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ACTIVE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171161"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r descs\n",
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['See if there is an snapshot present that should be removed.',\n",
       " 'Get the latest data and update state.',\n",
       " 'Mark the filter as being ordered if search has occurred.',\n",
       " \"Retrieve the distance parameters for the given geometry field, DCNL distance lookup value, and the distance lookup type. DCNL This is the most complex implementation of the spatial backends due to DCNL what is supported on geodetic geometry columns vs. what\\\\'s available on DCNL projected geometry columns.  In addition, it has to take into account DCNL the newly introduced geography column type introudced in PostGIS 1.5.\",\n",
       " 'Reset the marker to the first line.',\n",
       " 'Called to stop continuous host logging.',\n",
       " 'can verify that a location exists, using ccx block usage key',\n",
       " 'Decoding iterator. DCNL Decodes the input strings from the iterator using an IncrementalDecoder. DCNL errors and kwargs are passed through to the IncrementalDecoder DCNL constructor.',\n",
       " 'version known to trigger an INFO response message.',\n",
       " 'Evaluates the latest model checkpoint. DCNL Args: DCNL model: Instance of SkipThoughtsModel; the model to evaluate. DCNL losses: Tensor; the target cross entropy losses for the current batch. DCNL weights: A Tensor of weights corresponding to losses. DCNL saver: Instance of tf.train.Saver for restoring model Variables. DCNL summary_writer: Instance of FileWriter. DCNL summary_op: Op for generating model summaries.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(descs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = max(len(desc) for desc in descs)\n",
    "MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_split(descs):\n",
    "    chars = list(set(chain.from_iterable(desc for desc in descs)))\n",
    "    char_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "    ix_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    descs = [[char_ix[char] for char in desc] for desc in descs]\n",
    "    return descs, char_ix, ix_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 60 ms, total: 1.62 s\n",
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('|', 0), ('6', 1), ('<', 2), ('l', 3), ('-', 4)],\n",
       " [(0, '|'), (1, '6'), (2, '<'), (3, 'l'), (4, '-')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time descs, dir_map, rev_map = chars_split(descs)\n",
    "list(dir_map.items())[:5], list(rev_map.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(dir_map)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TT prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSequence(Sequence):\n",
    "    def __init__(self):\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(descs) / BATCH_SIZE))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = np.zeros((BATCH_SIZE, MAX_SEQ_LEN, VOCAB_SIZE))\n",
    "        \n",
    "        batch_ids = self._ids[idx * BATCH_SIZE: (idx + 1) * BATCH_SIZE]\n",
    "        for bi, di in enumerate(batch_ids):\n",
    "            for pi, wi in enumerate(descs[di]):\n",
    "                X[bi, pi, wi] = 1\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Generate new shuffle in between epochs.\"\"\"\n",
    "        self._ids = np.random.permutation(len(descs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, (128, 500, 95))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = TTSequence()\n",
    "len(tts), tts[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 300\n",
    "N_LAYERS = 2\n",
    "LSTM_CLASS = LSTM if not GPU_ACTIVE else CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 300)         475200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 300)         721200    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 95)          28595     \n",
      "=================================================================\n",
      "Total params: 1,224,995\n",
      "Trainable params: 1,224,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM_CLASS(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(N_LAYERS - 1):\n",
    "    model.add(LSTM_CLASS(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
